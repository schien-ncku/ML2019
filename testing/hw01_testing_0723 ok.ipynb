{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 b: -1.0 w: [0. 0. 0. 0. 0.] loss 186.80340312500041\n",
      "iteration: 200 b: 0.9287802027071551 w: [ 0.09515874  0.00370775 -0.01562409 -0.03742729  0.87504593] loss 13.003436609289535\n",
      "iteration: 400 b: 1.4336319260111718 w: [ 0.07471521  0.00274836  0.01216319 -0.10030348  0.89363923] loss 12.845071411533604\n",
      "iteration: 600 b: 1.6087872732917132 w: [ 6.91180116e-02 -3.13960823e-04  2.07349929e-02 -1.13052011e-01\n",
      "  8.93322875e-01] loss 12.828871082636752\n",
      "iteration: 800 b: 1.6704310606066544 w: [ 0.06750623 -0.00156413  0.02282673 -0.11581002  0.89223059] loss 12.826984920058106\n",
      "iteration: 1000 b: 1.6922415098101413 w: [ 0.0669532  -0.00192452  0.02328074 -0.11640731  0.89165298] loss 12.82675476786662\n",
      "iteration: 1200 b: 1.6999888970900294 w: [ 0.06674574 -0.00200541  0.02335613 -0.11652802  0.89140586] loss 12.826726009711484\n",
      "iteration: 1400 b: 1.702749788605196 w: [ 0.06666581 -0.00201636  0.02335718 -0.11654714  0.89130768] loss 12.826722362173477\n",
      "iteration: 1600 b: 1.703736318033416 w: [ 0.06663502 -0.00201428  0.02334978 -0.11654735  0.89126996] loss 12.826721894774675\n",
      "iteration: 1800 b: 1.7040896189117256 w: [ 0.06662324 -0.00201165  0.0233448  -0.11654554  0.89125572] loss 12.826721834452728\n",
      "iteration: 2000 b: 1.7042163820538028 w: [ 0.06661878 -0.00201011  0.02334231 -0.11654433  0.8912504 ] loss 12.826721826628955\n",
      "iteration: 2200 b: 1.7042619353938628 w: [ 0.06661711 -0.00200938  0.0233412  -0.11654374  0.89124843] loss 12.826721825610685\n",
      "iteration: 2400 b: 1.704278326682458 w: [ 0.06661649 -0.00200907  0.02334074 -0.11654347  0.8912477 ] loss 12.826721825477897\n",
      "iteration: 2600 b: 1.704284231090312 w: [ 0.06661625 -0.00200894  0.02334056 -0.11654336  0.89124743] loss 12.826721825460538\n",
      "iteration: 2800 b: 1.704286359866883 w: [ 0.06661617 -0.00200889  0.02334048 -0.11654332  0.89124734] loss 12.826721825458215\n",
      "iteration: 3000 b: 1.7042871279486462 w: [ 0.06661614 -0.00200887  0.02334046 -0.1165433   0.8912473 ] loss 12.826721825458016\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x_list, y_list = [], []\n",
    "\n",
    "df = pd.read_csv(\"train.csv\",encoding=\"Big5\", usecols = range(3, 27))\n",
    "redf = df.replace(['NR'], [0.0])\n",
    "array = np.array(redf).astype(float)\n",
    "\n",
    "for i in range(0, 4320, 18):\n",
    "    for j in range(24-5):#每15hr一刀\n",
    "        mat = array[i:i+18, j:j+5]# 取18列，0-8時的數據\n",
    "        label = array[i+5, j+5] # 取0-5時的資料，第10行是PM2.5\n",
    "        x_list.append(mat)\n",
    "        y_list.append(label)\n",
    "        \n",
    "x = np.array(x_list)\n",
    "y = np.array(y_list)\n",
    "x_train, y_train = x[0:3200], y[0:3200]\n",
    "\n",
    "# ydata = b + w * xdata\n",
    "b = 0 #初始b\n",
    "w = np.ones(5) #初始w\n",
    "lr = 1 #learning rate\n",
    "iteration = 3200 #次數\n",
    "lr_b = 0\n",
    "lr_w = np.zeros(5)\n",
    "\n",
    "# iterations\n",
    "for i in range(iteration):\n",
    "    b_grad = 0\n",
    "    w_grad = np.zeros(5)\n",
    "    for j in range (3200):#算 y = b + x1w1 + x2w2 + x3w3....  求所有3200的 b\n",
    "        b_grad += (y_train[j] - w.dot(x_train[j, 5, :]) - b)*(-1)\n",
    "        for k in range(5):#算所有的 w\n",
    "            w_grad[k] += (y_train[j] - w.dot(x_train[j, 5, :])- b)*(-x_train[j, 5, k])\n",
    "        \n",
    "    b_grad /= 3200\n",
    "    w_grad /= 3200\n",
    "        \n",
    "    #adagrade\n",
    "    lr_b += b_grad**2\n",
    "    lr_w += w_grad**2\n",
    "    \n",
    "    #update parmeters\n",
    "    b -= lr/lr_b**0.5*b_grad\n",
    "    w -= lr/lr_w**0.5*w_grad\n",
    "    \n",
    "\n",
    "    \n",
    "    if i%200 == 0:\n",
    "        loss = 0\n",
    "        for j in range(3200):\n",
    "            loss += (y_train[j] - w.dot(x_train[j, 5, :]) - b)**2\n",
    "        print('iteration:', i, 'b:', b, 'w:', w, 'loss', loss/3200)\n",
    "        #print('iteration:', i)\n",
    "        #print('b:', b)\n",
    "        #print('w:', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0 b: -1.0 w: [-27.99453931 -29.23129222 -30.32456405 -31.28423978 -32.05324926\n",
      " -32.66183658 -32.99547989 -32.88634597 -32.37777959] loss 57482217.17001729\n",
      "iteration: 200 b: 0.0040532046581372464 w: [ 0.05412202  0.00562513  0.017296   -0.00242113  0.02631235  0.05114754\n",
      " -0.21952251  0.18926708  0.87025247] loss 49.4332636818523\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-28021a94d132>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mb_grad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mw_grad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mb_grad\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[1;36m3200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x_list, y_list = [], []\n",
    "\n",
    "df = pd.read_csv(\"train.csv\",encoding=\"Big5\", usecols = range(3, 27))\n",
    "redf = df.replace(['NR'], [0.0])\n",
    "array = np.array(redf).astype(float)\n",
    "\n",
    "for i in range(0, 4320, 18):\n",
    "    for j in range(24-9):#每15hr一刀\n",
    "        mat = array[i:i+18, j:j+9]# 取18列，0-8時的數據\n",
    "        label = array[i+9, j+9] # 取0-9時的資料，第10行是PM2.5\n",
    "        x_list.append(mat)\n",
    "        y_list.append(label)\n",
    "        \n",
    "x = np.array(x_list)\n",
    "y = np.array(y_list)\n",
    "x_train, y_train = x[0:3200], y[0:3200]\n",
    "\n",
    "# ydata = b + w * xdata\n",
    "b = 0 #初始b\n",
    "w = np.ones(9) #初始w\n",
    "lr = 1 #learning rate\n",
    "iteration = 3200 #次數\n",
    "lr_b = 0\n",
    "lr_w = np.zeros(9)\n",
    "\n",
    "# iterations\n",
    "for i in range(iteration):\n",
    "    b_grad = 0\n",
    "    w_grad = np.zeros(9)\n",
    "    for j in range (3200):\n",
    "        b_grad += (y_train[j] - w.dot(x_train[j, 9, :]) - b)*(-1)\n",
    "        for k in range(9):\n",
    "            w_grad[k] += (y_train[j] - w.dot(x_train[j, 9, :])- b)*(-x_train[j, 9, k])\n",
    "        \n",
    "    b_grad /= 3200\n",
    "    w_grad /= 3200\n",
    "        \n",
    "    #adagrade\n",
    "    lr_b += b_grad**2\n",
    "    lr_w += w_grad**2\n",
    "    \n",
    "    #update parmeters\n",
    "    b -= lr/np.sqrt(lr_b)*b_grad\n",
    "    w -= lr/np.sqrt(lr_b)*w_grad\n",
    "    \n",
    "\n",
    "    \n",
    "    if i%200 == 0:\n",
    "        loss = 0\n",
    "        for j in range(3200):\n",
    "            loss += (y_train[j] - w.dot(x_train[j, 9, :]) - b)**2\n",
    "        print('iteration:', i, 'b:', b, 'w:', w, 'loss', loss/3200)\n",
    "        #print('iteration:', i)\n",
    "        #print('b:', b)\n",
    "        #print('w:', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
